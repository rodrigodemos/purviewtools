{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Orphan Servers\n",
    "\n",
    "When a data source is deleted in Purview, the corresponding assets are not deleted. This script is meant to identify servers that are not associated to any data source.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "To be able to use this notebook, you will need to have:\n",
    "- Purview Account details\n",
    "- A user authorized to access Purview APIs\n",
    "- A Python environment with the required libraries\n",
    "\n",
    "## Steps\n",
    "- Update notebook with your environment information (purview account name, working directory & entities/server types to look for)\n",
    "- Execute the cells in the notebook\n",
    "- Load data in Excel and compare the list of servers to the list of datasources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from io import BytesIO\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.purview.catalog import PurviewCatalogClient\n",
    "from azure.purview.scanning import PurviewScanningClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "purview_account = '[ADD YOUR PURVIEW ACCOUNT NAME]'\n",
    "\n",
    "working_directory = 'C:\\\\temp\\\\'\n",
    "\n",
    "entitiesFilter = [\n",
    "    'azure_sql_server',\n",
    "    'azure_cosmosdb_account',\n",
    "    'azure_storage_account'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purview_client(purview_account):\n",
    "    credential = DefaultAzureCredential()\n",
    "    client = PurviewCatalogClient(\n",
    "        endpoint=f'https://{purview_account}.purview.azure.com', \n",
    "        credential=credential,\n",
    "        logging_enable=True)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filter(entities):\n",
    "    entityTypes = [{\"entityType\": entity} for entity in entities]\n",
    "    filter = {\"or\": entityTypes}\n",
    "    return filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_body(keywords, filter):\n",
    "    search_body = {\n",
    "        'keywords': keywords if keywords else None,\n",
    "        'facets': None,\n",
    "        'filter': filter if filter else None,\n",
    "    }\n",
    "    return search_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_dataframe(purview_client, filter, keywords ='*'):\n",
    "    search_request = create_search_body(keywords, filter)\n",
    "    purview_search = purview_client.discovery.query(search_request=search_request)\n",
    "    search_df = pd.DataFrame.from_dict(purview_search['value'])\n",
    "\n",
    "    output_df = pd.DataFrame({\n",
    "        'name': search_df['name'],\n",
    "        'entityType': search_df['entityType'],\n",
    "        'createTime': pd.to_datetime(search_df['createTime'], unit='ms'),\n",
    "        'updateTime': pd.to_datetime(search_df['updateTime'], unit='ms')\n",
    "    })\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasources_to_dataframe():\n",
    "    credential = DefaultAzureCredential()\n",
    "    client = PurviewScanningClient(\n",
    "        endpoint=f'https://{purview_account}.scan.purview.azure.com', \n",
    "        credential=credential)\n",
    "    response = client.data_sources.list_all()\n",
    "    datasources = [datasource for datasource in response]\n",
    "\n",
    "    def extract_datasource_property(properties, propertyName):\n",
    "        if properties and propertyName in properties:\n",
    "            return properties[propertyName]\n",
    "        return None\n",
    "            \n",
    "    datasources_raw_df = pd.DataFrame(datasources)\n",
    "\n",
    "    datasources_df = pd.DataFrame({\n",
    "        'name': datasources_raw_df['name'],\n",
    "        'kind': datasources_raw_df['kind'],\n",
    "        'creationType': datasources_raw_df['creationType'],\n",
    "        'endpointInfo': datasources_raw_df['properties'].apply(lambda x: \n",
    "                                                               extract_datasource_property(x, 'serverEndpoint') if extract_datasource_property(x, 'serverEndpoint') \n",
    "                                                               else (extract_datasource_property(x, 'endpoint') if extract_datasource_property(x, 'endpoint') \n",
    "                                                                     else extract_datasource_property(x, 'accountUri'))),\n",
    "        'endpointPropertyName': datasources_raw_df['properties'].apply(lambda x: \n",
    "                                                               'serverEndpoint' if extract_datasource_property(x, 'serverEndpoint') \n",
    "                                                               else ('endpoint' if extract_datasource_property(x, 'endpoint') \n",
    "                                                                     else ('accountUri' if extract_datasource_property(x, 'accountUri') else None))),\n",
    "        # 'serverEndpoint': datasources_raw_df['properties'].apply(lambda x: extract_datasource_property(x, 'serverEndpoint')),\n",
    "        # 'endpoint': datasources_raw_df['properties'].apply(lambda x: extract_datasource_property(x, 'endpoint')),\n",
    "        # 'accountUri': datasources_raw_df['properties'].apply(lambda x: extract_datasource_property(x, 'accountUri')),\n",
    "        'resourceName': datasources_raw_df['properties'].apply(lambda x: extract_datasource_property(x, 'resourceName')),\n",
    "        'subscription': datasources_raw_df['properties'].apply(lambda x: extract_datasource_property(x, 'subscription')),\n",
    "        'resourceGroup': datasources_raw_df['properties'].apply(lambda x: extract_datasource_property(x, 'resourceGroup')),\n",
    "        'createdAt': datasources_raw_df['properties'].apply(lambda x: extract_datasource_property(x, 'createdAt')),\n",
    "        'lastModifiedAt': datasources_raw_df['properties'].apply(lambda x: extract_datasource_property(x, 'lastModifiedAt'))\n",
    "    })\n",
    "\n",
    "\n",
    "    return datasources_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(dataframe, file_path, filename):\n",
    "\n",
    "    #create directory from download_path if it doesn't exist\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "    output_file  = f'{file_path}\\{filename}'\n",
    "    pd.DataFrame.to_csv(dataframe, path_or_buf=output_file, index=False)\n",
    "    \n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'purview_initiated' not in globals():\n",
    "        purview_client = purview_client(purview_account)\n",
    "        purview_initiated = True\n",
    "    \n",
    "    filter = create_filter(entitiesFilter)\n",
    "\n",
    "    pv_sources_df = datasources_to_dataframe()\n",
    "    pv_search_df = query_to_dataframe(purview_client, filter)\n",
    "\n",
    "    fileTS = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    sources_file = f'pv_datasources_{fileTS}.csv'\n",
    "    servers_file = f'pv_servers_{fileTS}.csv'\n",
    "    export_to_csv(pv_sources_df, working_directory, sources_file)\n",
    "    export_to_csv(pv_search_df, working_directory, servers_file)\n",
    "    \n",
    "    print(f'Files exported successfully at: {working_directory}')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
